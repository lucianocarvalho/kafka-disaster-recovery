# Como o Kafka salva as mensagens no disco?

As mensagens do Kafka s√£o salvas dentro de uma parti√ß√£o: imut√°vel e append only. Uma parti√ß√£o n√£o pode ser separada entre multiplos brokers ou em m√∫ltiplos discos. Uma parti√ß√£o sempre ir√° por completo para um broker e essa parti√ß√£o ser√° replicada (por completo) em outro broker como r√©plicas in-sync.

As reten√ß√µes das mensagens lideram em como essas mensagens s√£o gerenciadas dentro do Kafka, quer a mensagem ter sido consumida ou n√£o. √â essa reten√ß√£o que coordena quando o Kafka tem que rodar o Log Cleaner e apagar mensagens antigas do disco. Sem ele, os brokers apenas aumentariam seu uso de disco para sempre.

O padr√£o das reten√ß√µes de mensagens √© de 7 dias, mas ajust√°vel conforme sua necessidade pela configura√ß√£o `retention.ms` em um t√≥pico.

## Segments

Para que o Kafka n√£o tenha que lidar com um arquivo gigantesco com milh√µes de mensagens, tanto pra dar append quanto para limpar as mensagens antigas, o Kafka escreve as mensagens dentro de um segmento: o segmento atual. Quando o segmento atinge seu limite m√°ximo (o que vamos ver mais pra baixo), o Kafka cria um novo segmento e esse passa a ser o segmento atual.

Os segmentos s√£o nomeados pelo seu offset base. O offset base tem que ser maior do que o √∫ltimo offset do √∫ltimo segmento criado e normalmente √© o primeiro offset daquele segmento.

Em um disco, a parti√ß√£o √© um diret√≥rio e cada segmento √© um arquivo.

Os tamanhos dos segments de log s√£o configurados pelo atributo `segment.bytes`.

Os tamanhos dos segmentos de index s√£o configurados pelo o atributo `segment.index.bytes`.

#### N√£o entendi

Digamos que temos 9 mensagens e dizemos pro Kafka que queremos separar as mensagens em segmentos de 3 mensagens cada. Sua separa√ß√£o em segmentos ficaria mais um menos assim:

- Segment 0: mensagens do offset 0 at√© o 3
- Segment 3: mensagens do offset 3 at√© o 6
- Segment 6: mensagens do offset 6 at√© o 9
- Segment 9: pr√≥ximas mensagens (10, 11, 12)

## Hands-on!

Vamos ver como isso fica dentro do Kafka.

Primeiro, para exemplificar, entramos em qualquer broker e criamos um t√≥pico novo com apenas uma parti√ß√£o:
```bash
kafka-topics --zookeeper zookeeper:2181 --topic storage  \
             --partitions 1 \
             --replication-factor 1 \
             --create
```

Agora vamos verificar em qual broker esse t√≥pico foi criado:

```bash
kafka-topics --zookeeper zookeeper:2181 --topic storage --describe
```
```text
Topic: storage  PartitionCount: 1   ReplicationFactor: 1    Configs:
    Topic: storage  Partition: 0    Leader: 3   Replicas: 3 Isr: 3
```

Podemos ver que a √∫nica parti√ß√£o desse t√≥pico foi criado no broker 3.

### Inspencionando a parti√ß√£o

Os segmentos dentro dessa stack s√£o escritos na pasta `/var/lib/kafka/data`, mas voc√™ pode ver onde os arquivos s√£o escritos dentro de cada broker com o comando `kafka-log-dirs`:

```bash
kafka-log-dirs --describe --bootstrap-server kafka1:9092 --topic-list storage
```

Dentro do broker 3 e dentro dessa pasta dos segmentos, voc√™ vai encontrar alguma estrutura parecida com isso:

```text
/storage-0
|____00000000000000000000.log
|____leader-epoch-checkpoint
|____00000000000000000000.timeindex
|____00000000000000000000.index
```

As mensagens s√£o escritas nesses segmentos de `log` üòÅ

Para inspencionar melhor ele, vamos publicar algumas mensagens com o Producer interativo.

```bash
kafka-console-producer --broker-list kafka1:9092 --topic storage
```

### Entendendo os arquivos

Pra cada segmento n√≥s temos 3 arquivos:

- segment.index
- segment.log
- segment.timeindex

O arquivo de .log √© onde realmente o arquivo √© guardado, onde os dados reais est√£o.
A estrutura dele √© ter um offset, alguns metadados e a sua mensagem.

Para que o Kafka n√£o tenha que buscar um offset em todo o arquivo do segmento e causar um overhead na busca, √© criado esse arquivo de `segment.index` que mapeiam os offset para onde eles se encontram dentro do `segment.log`. Esse arquivo do inde est√° sempre na mem√≥ria e √© utilizado busca bin√°ria para buscar suas respectivas mensagens.


Os arquivos de log seguem uma sem√¢ncia n√£o muito friendly, mas conseguimos ver os dados utilizando o `DumpLogSegments`:

```bash
kafka-run-class kafka.tools.DumpLogSegments \
        --deep-iteration --print-data-log \
        --files /var/lib/kafka/data/storage-0/00000000000000000000.log
```

```text
| offset: 10041 CreateTime: 1600490339425 keysize: -1 valuesize: 4 sequence: -1 headerKeys: [] payload: 9995
| offset: 10042 CreateTime: 1600490339425 keysize: -1 valuesize: 4 sequence: -1 headerKeys: [] payload: 9996
| offset: 10043 CreateTime: 1600490339425 keysize: -1 valuesize: 4 sequence: -1 headerKeys: [] payload: 9997
| offset: 10044 CreateTime: 1600490339425 keysize: -1 valuesize: 4 sequence: -1 headerKeys: [] payload: 9998
| offset: 10045 CreateTime: 1600490339425 keysize: -1 valuesize: 4 sequence: -1 headerKeys: [] payload: 9999
```

### Refer√™ncias:

- [How Kafka‚Äôs Storage Internals Work](https://thehoard.blog/how-kafkas-storage-internals-work-3a29b02e026)
- [What are the different logs under kafka data log dir](https://stackoverflow.com/questions/53744646/what-are-the-different-logs-under-kafka-data-log-dir)
- [A Practical Introduction to Kafka Storage Internals](https://medium.com/@durgaswaroop/a-practical-introduction-to-kafka-storage-internals-d5b544f6925f)